D:\programs\Anaconda\envs\pytorch\python.exe G:/笔记本数据保存/Y700数据互通/软件安装/chatgpt_academic-master/1.py
Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST\MNIST\raw\train-images-idx3-ubyte.gz
9913344it [00:03, 2654076.06it/s]                             
Extracting ./MNIST\MNIST\raw\train-images-idx3-ubyte.gz to ./MNIST\MNIST\raw

Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST\MNIST\raw\train-labels-idx1-ubyte.gz
29696it [00:00, 818793.52it/s]           
Extracting ./MNIST\MNIST\raw\train-labels-idx1-ubyte.gz to ./MNIST\MNIST\raw

Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST\MNIST\raw\t10k-images-idx3-ubyte.gz
1649664it [00:02, 691968.85it/s]                             
Extracting ./MNIST\MNIST\raw\t10k-images-idx3-ubyte.gz to ./MNIST\MNIST\raw

Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST\MNIST\raw\t10k-labels-idx1-ubyte.gz
5120it [00:00, ?it/s]                   
Extracting ./MNIST\MNIST\raw\t10k-labels-idx1-ubyte.gz to ./MNIST\MNIST\raw

VGG16(
  (block_1): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU()
    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  )
  (block_2): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU()
    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  )
  (block_3): Sequential(
    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU()
    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (5): ReLU()
    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU()
    (8): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  )
  (block_4): Sequential(
    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU()
    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (5): ReLU()
    (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU()
    (8): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  )
  (block_5): Sequential(
    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU()
    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (5): ReLU()
    (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU()
    (8): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=2048, out_features=4096, bias=True)
    (1): ReLU()
    (2): Linear(in_features=4096, out_features=4096, bias=True)
    (3): ReLU()
    (4): Linear(in_features=4096, out_features=10, bias=True)
  )
)
(tensor([[13298.7188, 28187.7070, 15024.9727, 15231.2461,  2169.1855, 13515.6035,
         -1739.8652,  9352.2979, -5196.0010, 17780.4883]],
       grad_fn=<AddmmBackward0>), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], grad_fn=<SoftmaxBackward0>))
Epoch: 001/010 | Batch 000/938 | Cost: 4681.4023
Epoch: 001/010 | Batch 120/938 | Cost: 0.4387
Epoch: 001/010 | Batch 240/938 | Cost: 0.1184
Epoch: 001/010 | Batch 360/938 | Cost: 0.3075
Epoch: 001/010 | Batch 480/938 | Cost: 0.0544
Epoch: 001/010 | Batch 600/938 | Cost: 0.1094
Epoch: 001/010 | Batch 720/938 | Cost: 0.2038
Epoch: 001/010 | Batch 840/938 | Cost: 0.3409
Epoch: 001/010 Train Acc.: 97.22% | Validation Acc.: 97.37%
Time elapsed: 1.77 min
Epoch: 002/010 | Batch 000/938 | Cost: 0.0510
Epoch: 002/010 | Batch 120/938 | Cost: 0.0990
Epoch: 002/010 | Batch 240/938 | Cost: 0.0400
Epoch: 002/010 | Batch 360/938 | Cost: 0.2403
Epoch: 002/010 | Batch 480/938 | Cost: 0.0890
Epoch: 002/010 | Batch 600/938 | Cost: 0.0258
Epoch: 002/010 | Batch 720/938 | Cost: 0.1063
Epoch: 002/010 | Batch 840/938 | Cost: 0.1937
Epoch: 002/010 Train Acc.: 96.46% | Validation Acc.: 96.58%
Time elapsed: 3.46 min
Epoch: 003/010 | Batch 000/938 | Cost: 0.0653
Epoch: 003/010 | Batch 120/938 | Cost: 0.0938
Epoch: 003/010 | Batch 240/938 | Cost: 0.1295
Epoch: 003/010 | Batch 360/938 | Cost: 0.0450
Epoch: 003/010 | Batch 480/938 | Cost: 0.0014
Epoch: 003/010 | Batch 600/938 | Cost: 0.0564
Epoch: 003/010 | Batch 720/938 | Cost: 0.0395
Epoch: 003/010 | Batch 840/938 | Cost: 0.1050
Epoch: 003/010 Train Acc.: 98.69% | Validation Acc.: 98.44%
Time elapsed: 5.21 min
Epoch: 004/010 | Batch 000/938 | Cost: 0.0323
Epoch: 004/010 | Batch 120/938 | Cost: 0.0176
Epoch: 004/010 | Batch 240/938 | Cost: 0.0410
Epoch: 004/010 | Batch 360/938 | Cost: 0.1500
Epoch: 004/010 | Batch 480/938 | Cost: 0.0309
Epoch: 004/010 | Batch 600/938 | Cost: 0.0570
Epoch: 004/010 | Batch 720/938 | Cost: 0.0226
Epoch: 004/010 | Batch 840/938 | Cost: 0.0388
Epoch: 004/010 Train Acc.: 98.58% | Validation Acc.: 98.61%
Time elapsed: 6.95 min
Epoch: 005/010 | Batch 000/938 | Cost: 0.0438
Epoch: 005/010 | Batch 120/938 | Cost: 0.0706
Epoch: 005/010 | Batch 240/938 | Cost: 0.0640
Epoch: 005/010 | Batch 360/938 | Cost: 0.0057
Epoch: 005/010 | Batch 480/938 | Cost: 0.0117
Epoch: 005/010 | Batch 600/938 | Cost: 0.0568
Epoch: 005/010 | Batch 720/938 | Cost: 0.0714
Epoch: 005/010 | Batch 840/938 | Cost: 0.0560
Epoch: 005/010 Train Acc.: 98.67% | Validation Acc.: 98.60%
Time elapsed: 8.69 min
Epoch: 006/010 | Batch 000/938 | Cost: 0.0034
Epoch: 006/010 | Batch 120/938 | Cost: 0.0105
Epoch: 006/010 | Batch 240/938 | Cost: 0.0049
Epoch: 006/010 | Batch 360/938 | Cost: 0.0330
Epoch: 006/010 | Batch 480/938 | Cost: 0.0009
Epoch: 006/010 | Batch 600/938 | Cost: 0.0723
Epoch: 006/010 | Batch 720/938 | Cost: 0.0010
Epoch: 006/010 | Batch 840/938 | Cost: 0.0504
Epoch: 006/010 Train Acc.: 98.97% | Validation Acc.: 98.79%
Time elapsed: 10.47 min
Epoch: 007/010 | Batch 000/938 | Cost: 0.0045
Epoch: 007/010 | Batch 120/938 | Cost: 0.0649
Epoch: 007/010 | Batch 240/938 | Cost: 0.0027
Epoch: 007/010 | Batch 360/938 | Cost: 0.1334
Epoch: 007/010 | Batch 480/938 | Cost: 0.0025
Epoch: 007/010 | Batch 600/938 | Cost: 0.0316
Epoch: 007/010 | Batch 720/938 | Cost: 0.0472
Epoch: 007/010 | Batch 840/938 | Cost: 0.0400
Epoch: 007/010 Train Acc.: 97.68% | Validation Acc.: 98.02%
Time elapsed: 12.26 min
Epoch: 008/010 | Batch 000/938 | Cost: 0.0892
Epoch: 008/010 | Batch 120/938 | Cost: 0.0690
Epoch: 008/010 | Batch 240/938 | Cost: 0.1490
Epoch: 008/010 | Batch 360/938 | Cost: 0.0496
Epoch: 008/010 | Batch 480/938 | Cost: 0.0728
Epoch: 008/010 | Batch 600/938 | Cost: 0.1451
Epoch: 008/010 | Batch 720/938 | Cost: 0.0095
Epoch: 008/010 | Batch 840/938 | Cost: 0.0088
Epoch: 008/010 Train Acc.: 99.17% | Validation Acc.: 98.96%
Time elapsed: 14.04 min
Epoch: 009/010 | Batch 000/938 | Cost: 0.0065
Epoch: 009/010 | Batch 120/938 | Cost: 0.0012
Epoch: 009/010 | Batch 240/938 | Cost: 0.0255
Epoch: 009/010 | Batch 360/938 | Cost: 0.1439
Epoch: 009/010 | Batch 480/938 | Cost: 0.0103
Epoch: 009/010 | Batch 600/938 | Cost: 0.0970
Epoch: 009/010 | Batch 720/938 | Cost: 0.0154
Epoch: 009/010 | Batch 840/938 | Cost: 0.0520
Epoch: 009/010 Train Acc.: 99.04% | Validation Acc.: 98.83%
Time elapsed: 15.83 min
Epoch: 010/010 | Batch 000/938 | Cost: 0.0185
Epoch: 010/010 | Batch 120/938 | Cost: 0.0848
Epoch: 010/010 | Batch 240/938 | Cost: 0.0486
Epoch: 010/010 | Batch 360/938 | Cost: 0.6423
Epoch: 010/010 | Batch 480/938 | Cost: 0.1444
Epoch: 010/010 | Batch 600/938 | Cost: 0.0308
Epoch: 010/010 | Batch 720/938 | Cost: 0.0772
Epoch: 010/010 | Batch 840/938 | Cost: 0.0107
Epoch: 010/010 Train Acc.: 98.90% | Validation Acc.: 98.66%
Time elapsed: 17.61 min
Total Training Time: 17.61 min
Test accuracy: 98.66%
torch.Size([64, 1, 64, 64])

Process finished with exit code 0
